% !TEX root = LMThesisNicchi.tex

\chapter{Experimental Evaluation}

In this chapter we will illustrate the results obtained during the experimental evaluation of BlueTracer.

We first tested the tool on a set of benign applications performing different tasks, in order to assess its run-time overhead.

Then, we validated BlueTracer using \textit{Al-Khaser} \cite{AlK}, a popular open-source project employed to assess how stealthy a malware analysis system is with respect to a large portion of public evasion techniques used by real malware families.

\iffalse
Finally, we employed BlueTracer to analyze a group of highly evasive real malware samples collected by Joe Security, the proclaimed technology leader for the analysis of evasive malware.
\fi

\iffalse
If JoeBox added differentiate machines
\fi
All the tests were conducted on a VirtualBox (version 5.2.6)  Virtual Machine with 1 CPU core and 3 GB of RAM running Windows 7 32-bit. The specifications of the host machine are:
\begin{itemize}
\item \textbf{Operating System:} Linux Mint 17.3 
\item \textbf{Processor:} Intel Core i7-3537U CPU @ 2.00 GHz $\times$ 2
\item \textbf{RAM:} 8 GBs  
\end{itemize}
 

\section{Run-Time Overhead Assessment}

In order to evaluate the run-time overhead introduced by BlueTracer we tested it with a number of benign applications exercising a large number of functions. In order to experiment with a wide range of different functionalities, we picked a set of well-known Windows applications performing a variety of jobs. We grouped these applications based on the task they carry out, as shown below:

\begin{itemize}
\item \textbf{Collection of system information}
	   \begin{itemize}
	   \item \texttt{Systeminfo.} It outputs a summary of OS-environment parameters. 
	   \item \texttt{System File Checker (SFC).} It scans for corruptions in system files.
	   \item \texttt{Check Disk}. It checks the disks' integrity.
	   \item \texttt{IPConfig}. It displays TCP/IP network configuration values.
	   \item \texttt{Netstat}. It can show active TCP connections as well as TCP and UDP ports on which the computer is listening.
	   \item \texttt{Driver Query}. It presents the list of installed drivers and their properties.
	   \item \texttt{Windows Assessment Tools (WinSAT).} It  measures a number of performance characteristics and reports them.
	   \item \texttt{Powercfg.} It enables to search for common energy-efficiency problems. 
	   \end{itemize}
\item \textbf{Compression programs}
		\begin{itemize}
		\item \texttt{7zip.}. Its default output extension is \texttt{.7z}.
		\item \texttt{IZArc.} Its default output extension is \texttt{.zip}.
		\item \texttt{WinRar.} Its default output extension is \texttt{.rar}.
		\end{itemize}
\item \textbf{Encryption Utilities}
		\begin{itemize}
		\item \texttt{Cipher.} It uses Encrypting File System (ESF), based on DESX. 
		\item \texttt{OpenSSL.} It was configured to employ 256-bit CBC AES.
		\item \texttt{Crypt.} It adopts RC2 block encryption.
		\end{itemize}
\item \textbf{Hashing Utilities}
		\begin{itemize}
		\item \texttt{File Checksum Integrity Verifier (FCIV).} It was set to use both MD5 and SHA1.
		\item \texttt{TurboSFV.} It was configured to adopt SHA3-224. 
		\end{itemize}
\end{itemize}

We first recorded the native execution time for each of the aforementioned applications. Then, we ran them under BlueTracer, logging the respective execution times. Specifically, the following BlueTracer modes of operation were employed:

\begin{itemize}
\item \textbf{Empty Image.} All image notification functions are empty, that is, they just increase a global counter value. This means that no analysis routines are inserted at run-time. 
\item \textbf{Empty Routine.} All analysis routines are empty, i.e., all they do is, once again, increase a global counter value.
\item \textbf{Main Image.} Only Native APIs and APIs being directly invoked from the main executable of the pinned application are traced. This is BlueTracer's default mode of operation. 
\item \textbf{Complete.} Every event is traced, also including Native APIs and APIs being invoked outside the main executable.
\end{itemize}

We tested every benign application in the previous page adopting each of the above operation modes, which can be set using BlueTracer's configuration file. Essentially, \textbf{Empty Image} and \textbf{Empty Routine} were utilized to determine the run-time overhead introduced just by the Pin's framework, when no analysis is actually performed. On the contrary, \textbf{Main Image} was adopted to show BlueTracer's overhead during a typical use of the tool, as \textbf{Main Image} is BlueTracer's default mode. Lastly, \textbf{Complete} was employed to determine how BlueTracer's behaves under heavy stress conditions.

We tested each application three times and then recorded the average execution time. For the compression programs, the file being compressed was the Puppy Linux ISO (\texttt{xenialpup-7.5-uefi.iso}), of size 332 MBs. On the other hand, for the encryption and hashing utilities, we used the Ubuntu 18.04 ISO (\texttt{ubuntu-18.04-desktop-amd64}), the size of which is 1.8 GBs. During the tests, we also decided to stop the execution of the pinned application if, after it had been running for more than 10 minutes, the log file was greater than 5 GBs. This had to be done due to the hard drive limitations of the testing platform.      

The recorded execution times can be observed from \textit{Table 4.1}. As it can be seen, as more demanding modes of operation are employed, the run-time increases, although the increment is not uniform, but is actually quite variable across the different applications.

In light of this, to actually quantify the run-time overhead we decided to adopt the following metric:

\begin{align*}
\text{Overhead per Event} = \frac{T_{instrumented} - T_{native}}{Events}
\end{align*}

where:
\begin{itemize}
\item $T_{instrumented}$ is the application's execution time when executed under BlueTracer with the \textbf{Complete} mode of operation enabled. We chose the \textbf{Complete} mode of operation to quantify the overhead per event in the worst-case situation.
\item $T_{native}$ is the application's native execution time.
\item $Events$ is the total number of Native API and API calls performed by the analyzed application.
\end{itemize}

\textit{Table 4.2} lists the overhead per event value of each benign application for which the execution time in the \textbf{Complete} mode of operation could be obtained. In this case we can see that the typical overhead is approximately up to 22$\times10^{-5}$ seconds, with the compression programs being an exception, as they have a greater overhead per event value than the rest.

\vspace*{0.8cm}
\begin{sidewaystable}
\centering
%\begin{tabular}{cccccc}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
\begin{tabularx}{\linewidth}{*{6}{Y}}

\hline
\hline
   \textbf{Application} & \specialcell{ \textbf{Native} \\ \textbf{(s)}} & \specialcell{ \textbf{Empty Image} \\ \textbf{(s)}} & \specialcell{ \textbf{Empty Routine} \\ \textbf{(s)}} & \specialcell{ \textbf{Main Image} \\ \textbf{(s)}} & \specialcell{ \textbf{Complete} \\ \textbf{(s)}} \\
\hline
\texttt{Systeminfo}      & 5.894    & 9.686  & 12.869 & 15.694 & 26.398     \\
\texttt{SFC}          & 218.251 & 222.065 & 226.125 & 230.869 & 245.476       \\
\texttt{Check Disk}       & 101.570     & 171.94 & 181.429 & 454.649 & 600+      \\
\texttt{IPConfig}       & 0.105     & 4.257 & 8.421 & 9.599 & 13.181      \\
\texttt{Netstat} & 0.085 & 2.563 & 4.630 & 6.902 & 21.129       \\
\texttt{DriverQuery} & 1.168 & 6.663 & 9.786 & 34.074 & 68.668      \\
\texttt{WinSat}       & 163.175     & 212.496 & 221.012 & 273.641 & 600+      \\
\texttt{PowerCFG} & 61.333      & 73.325 & 80.018 & 132.466 & 273.882       \\
\texttt{7zip}       & 175.526     & 212.000 & 225.091 & 227.985 & 233.792      \\
\texttt{IZArc}      & 30.920     & 52.878 & 56.631 & 61.066 & 65.770      \\
\texttt{WinRar} & 155.674 & 192.638 & 198.804 & 208.606 & 215.455      \\
\texttt{Cipher} & 0.028 & 1.817 & 3.787 & 4.435 & 5.064       \\
\texttt{OpenSSL} & 24.769 & 33.183 & 34.308 & 47.006 & 1524.763      \\
\texttt{Crypt} & 65.392 & 140.048 & 142.979 & 572.353 & 600+      \\
\texttt{FCIV} & 10.807 & 25.113 & 28.144 & 56.329 & 87.948       \\
\texttt{TurboSFV} & 34.412 & 57.705 & 62.639 & 66.439 & 74.657
\\
\hline
\end{tabularx}
\vspace{0.2cm}
\caption{Execution times of instrumented benign applications}

\end{sidewaystable}

\iffalse
\begin{table}
\centering
%\begin{tabular}{cccccc}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
\begin{tabularx}{\linewidth}{*{4}{Y}}
\hline
\hline
\cline{1-2}
   \textbf{Application} & \specialcell{ \textbf{Complete} \\ \textbf{(s)}} & \textbf{Events} & \specialcell{ \textbf{Overhead / Event} \\ \textbf{(s)}} \\
\hline
\texttt{Systeminfo}      & 26.398    & 387 476      \\
\texttt{System File Checker}          & each        & 0.01       \\
\texttt{Check Disk}       & stuffed     & 92.50      \\
\texttt{IPConfig}       & stuffed     & 33.33      \\
\texttt{Netstat} & frozen      & 8.99       \\
\texttt{DriverQuery}       & stuffed     & 92.50      \\
\texttt{WinSat}       & stuffed     & 33.33      \\
\texttt{PowerCFG} & frozen      & 8.99       \\
\texttt{7zip}       & stuffed     & 92.50      \\
\texttt{IZArc}      & stuffed     & 33.33      \\
\texttt{WinRar} & frozen      & 8.99       \\
\texttt{Cipher} & frozen      & 8.99       \\
\texttt{OpenSSL}       & stuffed     & 92.50      \\
\texttt{Crypt}      & stuffed     & 33.33      \\
\texttt{FCIV} & frozen      & 8.99       \\
\hline
\end{tabularx}
\caption{Run-time overhead for benign applications}
\end{table}
\fi

\vspace*{0.8cm}
\begin{sidewaystable}
\centering
%\begin{tabular}{cccccc}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
\begin{tabularx}{\linewidth}{*{6}{Y}}

\hline
\hline
\cline{1-2}
   \textbf{Application} & \specialcell{ \textbf{Native} \\ \textbf{(s)}} & \specialcell{ \textbf{Complete} \\ \textbf{(s)}} & \textbf{Events} & \specialcell{ \textbf{Overhead per Event} \\  \textbf{($10^-5$ s)} }  \\
\hline
\texttt{Systeminfo}      & 5.894    & 26.398  & 387 476 & $5.291$    \\
\texttt{SFC}          & 218.251 & 245.476 & 333 781 & $8.156$ \\
\texttt{IPConfig}       & 0.105 & 13.181 & 94 313 & $13.864$      \\
\texttt{Netstat} & 0.085 & 21.129 & 542 649 & $3.878$       \\
\texttt{DriverQuery} & 1.168 & 68.668 & 1 735 859 & $3.860$            \\
\texttt{PowerCFG} & 61.333 & 273.882 & 4 497 247 & $4.726$       \\
\texttt{7zip}       & 175.526 & 233.792 & 146 578 & $39.751$      \\
\texttt{IZArc}      & 30.920 & 65.770 & 109 142 & $31.931$      \\
\texttt{WinRar} & 155.674 & 215.455 & 84 329 & $70.890$      \\
\texttt{Cipher} & 0.028 & 4.435 & 24 141 & $18.255$           \\
\texttt{OpenSSL} & 24.769 & 1524.763 & 57 410 809 & $2.613$                \\
\texttt{FCIV} & 10.807 & 87.948 & 725 133 &  $10.638$               \\
\texttt{TurboSFV} & 34.412 & 74.657 & 183 455 & $21.937$ 
\\
\hline
\end{tabularx}
\vspace{0.2cm}
\caption{Run-time overhead for benign applications}

\end{sidewaystable}

\vspace{-2cm}
\section{Al-Khaser}
Al-Khaser \cite{AlK} is a popular open-source application which performs a large number of common checks employed by malware families to determine if they are being executed in an analysis environment. It is typically utilized to assess how stealthy and well hidden a malware analysis system is. For this reason, we chose Al-Khaser as our main validation tool.

The checks implemented by Al-Khaser are divided into categories, with the most significant ones being the following:
\begin{itemize}
\item \textbf{Anti-Debugging}, aimed at detecting the presence of a debugger.
\item \textbf{Anti-Sandbox Timing-based}, the purpose of which is to let sandboxes time out in order to defy analysis. 
\item \textbf{Human Interaction Detection}, which seek to discover the presence of a sandbox by looking for the lack of human interaction with the system.
\item \textbf{Anti-Virtualization}, which have the objective of exposing the use of virtualization and full-system emulation. 
\item \textbf{Anti-Analysis}, aimed at uncovering the employment of common analysis tools (e.g OllyDbg, IDA Pro, etc. ).
\end{itemize}  

When Al-Khaser's executable is run, all the checks are performed and the outcome of each one of them can be easily observed from the command line: \texttt{GOOD} is printed if the analysis product succeeded at remaining hidden, and \texttt{BAD} otherwise. 

To validate BlueTracer, Al-Khaser was run under it in the default \textbf{Main Image} mode. The result was that BlueTracer managed to remain undetected with respect to all the checks performed by Al-Khaser. From this outcome we obtained a first confirmation of BlueTracer's ability to hide its presence. 

Furthermore, to also validate BlueTracer's tracing power, we analyzed the logs obtained when running Al-Khaser, with the objective of finding evidence of the performed evasion checks.
Even in this case, BlueTracer performed well, as the majority of the checks could easily be deduced from the log file. 

Let us now show how some of these checks appeared on the log, in order to give a better idea of what BlueTracer is capable of. To be as clear as possible, we will use the same checks categorization as Al-Khaser's.

\subsection{Anti-Debugging}

Anti-debugging checks are essentially aimed at determining if a program is running under a debugger. As already mentioned in section 2.1.5, there exist Windows APIs whose objective is exactly to discover if the calling process is being debugged.
A well-known API of this kind is \texttt{IsDebuggerPresent}, which returns a nonzero value if the calling process is running in the context of a debugger and zero otherwise. Such API is employed in one of Al-Khaser's anti-debugging checks and is appropriately recorded by BlueTracer (\textit{Listing 4.1}). As it can be seen below, the return value is zero, as no debugger is detected.

\vspace{0.5cm}
\lstset{
    language=C++,
    frame=tb, % draw a frame at the top and bottom of the code block
    tabsize=4, % tab space width
    showstringspaces=false, % don't mark spaces in strings
    numbers=none, % display line numbers on the left
    commentstyle=\color{ao}, % comment color
    keywordstyle=\color{blue}, % keyword color
    stringstyle=\color{red}, % string color
    basicstyle=\footnotesize\ttfamily,
    basewidth = {.48em}
}
\begin{lstlisting}[caption={Log entry relative to \texttt{IsDebuggerPresent}},captionpos=b]
~~3160~~ 562 kernel32.dll!IsDebuggerPresent
~~3160~~ 563 KERNELBASE.dll!IsDebuggerPresent
563    executed KERNELBASE.dll!IsDebuggerPresent =>
563 	retval: 0x0 (name=Return value, type=(long/int), size=0x4)
\end{lstlisting}
\lstset{
    language=C++,
    frame=tb, % draw a frame at the top and bottom of the code block
    tabsize=4, % tab space width
    showstringspaces=false, % don't mark spaces in strings
    numbers=left, % display line numbers on the left
    commentstyle=\color{ao}, % comment color
    keywordstyle=\color{blue}, % keyword color
    stringstyle=\color{red}, % string color
    basicstyle=\footnotesize\ttfamily,
    basewidth = {.48em}
}

Another popular Windows API for debug detection is \texttt{CheckRemoteDebuggerPresent}, which determines if the specified process is being debugged by a "remote" debugger, i.e., a debugger residing in parallel and different process. Its second argument is a pointer to a boolean, which is set to true if the provided process is being debugged, or false otherwise. Al-Khaser also adopts this API, and, again, BlueTracer correctly logged its invocation (\textit{Listing 4.2}). In addition, it is worth noting that the output value for the second argument (\texttt{arg 1}) is 
false (\texttt{0x0}), thus showing once more that a debugger was not discovered.   

\vspace{0.5cm}
\lstset{
    language=C++,
    frame=tb, % draw a frame at the top and bottom of the code block
    tabsize=4, % tab space width
    showstringspaces=false, % don't mark spaces in strings
    numbers=none, % display line numbers on the left
    commentstyle=\color{ao}, % comment color
    keywordstyle=\color{blue}, % keyword color
    stringstyle=\color{red}, % string color
    basicstyle=\footnotesize\ttfamily,
    basewidth = {.48em}
}
\begin{lstlisting}[caption={Log entry relative to \texttt{CheckRemoteDebuggerPresent}},captionpos=b]
~~3160~~ 1450 kernel32.dll!CheckRemoteDebuggerPresent
1450 	arg 0: 0xffffffff (name=hProcess, type=DWORD, size=0x4)
1450 	arg 1: 0x002bf710 => 0x0 (name=pbDebuggerPresent, type=(long/int)*, size=0x4)
1450    executed kernel32.dll!CheckRemoteDebuggerPresent =>
1450 	arg 1: 0x002bf710 => 0x0 (name=pbDebuggerPresent, type=(long/int)*, size=0x4)
1450 	retval: 0x1 (name=Return value, type=(long/int), size=0x4)
\end{lstlisting}
\lstset{
    language=C++,
    frame=tb, % draw a frame at the top and bottom of the code block
    tabsize=4, % tab space width
    showstringspaces=false, % don't mark spaces in strings
    numbers=left, % display line numbers on the left
    commentstyle=\color{ao}, % comment color
    keywordstyle=\color{blue}, % keyword color
    stringstyle=\color{red}, % string color
    basicstyle=\footnotesize\ttfamily,
    basewidth = {.48em}
}

Debugger detection is not only achieved through the use of Windows APIs. In fact, there are also some Native APIs which can be used for this purpose. One of them is \texttt{NtQueryInformationProcess}, which retrieves information related to the specified process. When invoked 
  

\subsection{Anti-Sandbox Timing-based}
\subsection{Human Interaction Detection}
\subsection{Anti-Virtualization}
\subsection{Anti-Analysis}


\iffalse
\section{JoeBox}
\fi

\section{Conclusions}